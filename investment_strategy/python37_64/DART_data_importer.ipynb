{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DART Open API를 이용해 기업 공시 정보를 가져온다. \n",
    "\n",
    "DART Open API 사용 연습\n",
    "\n",
    "해당 코드는 Python 3.5/3.7, 32bit/64bit 상관 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from urllib.request import Request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as elemTree\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DART Open API와 연결\n",
    "\n",
    "DART API에는 4가지 정보가 있고, 각 정보는 더 세부적으로 나뉜다. \n",
    "1. 공시정보\n",
    "2. 사업보고서 주요정보\n",
    "3. 상장기업 재무정보\n",
    "4. 지분공시 종합정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./DART_password.txt', 'r') as f:\n",
    "    API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crtfc_key = '?crtfc_key=' + API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 공시정보: \n",
    "    - 공시검색: 공시 유형별, 회사별, 날짜별 등 여러가지 조건으로 공시보고서 검색기능을 제공합니다.\n",
    "    - 기업개황: DART에 등록되어있는 기업의 개황정보를 제공합니다.\n",
    "    - 공시서류원본파일: 공시보고서 원본파일을 제공합니다.\n",
    "    - 고유번호: DART에 등록되어있는 공시대상회사의 고유번호,회사명,대표자명,종목코드, 최근변경일자를 파일로 제공합니다.\n",
    "\n",
    "기타 세부사항은 API doc에서 확인: https://opendart.fss.or.kr/guide/detail.do?apiGrpCd=DS001&apiId=2019001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 공시정보 base URLs\n",
    "\n",
    "DART_list_json = 'https://opendart.fss.or.kr/api/list.json' # 공시검색\n",
    "DART_company_json = 'https://opendart.fss.or.kr/api/company.json' # 기업개황\n",
    "DART_document_xml = 'https://opendart.fss.or.kr/api/document.xml' # 공시서류원본파일\n",
    "DART_corpCode_xml = 'https://opendart.fss.or.kr/api/corpCode.xml' # 고유번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_parameter(key, value):\n",
    "    return '&' + str(key) + '=' + str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DART_annc_info(info_type, **kwargs):\n",
    "    parameters = ''\n",
    "    for k, v in kwargs.items():\n",
    "        parameters += to_parameter(k,v)\n",
    "    \n",
    "    if info_type == 'list':\n",
    "        return DART_list_json + crtfc_key + parameters\n",
    "    elif info_type == 'company':\n",
    "        return DART_company_json + crtfc_key + parameters\n",
    "    elif info_type == 'document':\n",
    "        return DART_document_xml + crtfc_key + parameters\n",
    "    elif info_type == 'corpCode':\n",
    "        return DART_corpCode_xml + crtfc_key + parameters\n",
    "    else:\n",
    "        print('Wrong info_type. Choose from:')\n",
    "        print('''\n",
    "        1. \"list\": 공시검색\n",
    "        2. \"company\": 기업개활\n",
    "        3. \"document\": 공시서류원본파일\n",
    "        4. \"corpCode\": 고유번호\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DART_get_response(request_url):\n",
    "    req = urlopen(request_url)\n",
    "    response = req.read().decode('utf8')\n",
    "    \n",
    "    try:\n",
    "        result = ('json', json.loads(response))\n",
    "    except JSONDecodeError:\n",
    "        result = ('xml', elemTree.fromstring(response))\n",
    "    except:\n",
    "        print(\"An error occurred: \", sys.exc_info()[0])\n",
    "        return 0\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://opendart.fss.or.kr/api/list.json?crtfc_key=407c1fe7fc7a1a183002c6d5f981408662cd879e&corp_code=00919966&bgn_de=20130801&end_de=20150815'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_url = DART_annc_info('list', corp_code='00919966', bgn_de='20130801', end_de='20150815')\n",
    "req_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('json',\n",
       " {'status': '000',\n",
       "  'message': '정상',\n",
       "  'page_no': 1,\n",
       "  'page_count': 10,\n",
       "  'total_count': 9,\n",
       "  'total_page': 1,\n",
       "  'list': [{'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '분기보고서 (2015.03)',\n",
       "    'rcept_no': '20150601000841',\n",
       "    'flr_nm': '신라젠',\n",
       "    'rcept_dt': '20150601',\n",
       "    'rm': '정'},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '주요사항보고서(중요한자산양수도결정)',\n",
       "    'rcept_no': '20150430001501',\n",
       "    'flr_nm': '신라젠',\n",
       "    'rcept_dt': '20150430',\n",
       "    'rm': ''},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '[기재정정]사업보고서 (2014.12)',\n",
       "    'rcept_no': '20150423000246',\n",
       "    'flr_nm': '신라젠',\n",
       "    'rcept_dt': '20150423',\n",
       "    'rm': '연'},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '[기재정정]사업보고서 (2014.12)',\n",
       "    'rcept_no': '20150420000169',\n",
       "    'flr_nm': '신라젠',\n",
       "    'rcept_dt': '20150420',\n",
       "    'rm': '정연'},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '사업보고서 (2014.12)',\n",
       "    'rcept_no': '20150415000002',\n",
       "    'flr_nm': '신라젠',\n",
       "    'rcept_dt': '20150415',\n",
       "    'rm': '정연'},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '연결감사보고서 (2014.12)',\n",
       "    'rcept_no': '20150414001753',\n",
       "    'flr_nm': '삼일회계법인',\n",
       "    'rcept_dt': '20150414',\n",
       "    'rm': ''},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '감사보고서 (2014.12)',\n",
       "    'rcept_no': '20150408001181',\n",
       "    'flr_nm': '삼일회계법인',\n",
       "    'rcept_dt': '20150408',\n",
       "    'rm': ''},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '[기재정정]감사보고서 (2013.12)',\n",
       "    'rcept_no': '20140327000924',\n",
       "    'flr_nm': '남일회계법인',\n",
       "    'rcept_dt': '20140327',\n",
       "    'rm': ''},\n",
       "   {'corp_code': '00919966',\n",
       "    'corp_name': '신라젠',\n",
       "    'stock_code': '215600',\n",
       "    'corp_cls': 'K',\n",
       "    'report_nm': '감사보고서 (2013.12)',\n",
       "    'rcept_no': '20140227000130',\n",
       "    'flr_nm': '남일회계법인',\n",
       "    'rcept_dt': '20140227',\n",
       "    'rm': '정'}]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DART_get_response(req_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공시시간 크롤링\n",
    "\n",
    "문의결과, DART API는 현재 공시시간 정보를 제공하지 않는다. (아직 시범운영기간임을 감안하긴 해야한다.)\n",
    "\n",
    "따라서, 최근 공시 페이지는 직접 크롤링하기로 하였다. 다소 번거롭지만 API에서 지원이 되기 전까진 DART API에서 기본적인 공시 정보를 가져오고, 분단위의 공시시간이 필요한 경우 해당 날짜의 최근 공시를 크롤링한 결과와 대조해 결과를 매칭시키도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='color:red;'>TODO: 여러 날짜의 DailyAnnc 를 모아야한다. Class화 하는 것은 어떨까? 하지만 Class화 할 이유가 있을까? 고민해보자. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_annc_list_bs(date):\n",
    "    date_regex = re.compile(r'^\\d{4}\\.\\d{2}\\.\\d{2}$')\n",
    "    if not date_regex.match(date):\n",
    "        print(\"Error: Date format should be - yyyy.mm.dd\")\n",
    "        return 0\n",
    "    \n",
    "    recent_annc_list_bs = []\n",
    "    \n",
    "    for page in range(1, 11):\n",
    "        recent_annc_url = f'http://dart.fss.or.kr/dsac001/mainK.do?selectDate={date}&currentPage={page}&sort=&series=&mdayCnt=0#'\n",
    "        recent_annc_req = urlopen(recent_annc_url)\n",
    "        recent_annc_bs = bs(recent_annc_req, 'html.parser')\n",
    "        recent_annc_list_bs += recent_annc_bs.select('div.table_list > table > tr')\n",
    "    \n",
    "    recent_annc_list_bs = [x for x in recent_annc_list_bs if '검색된 자료가 없습니다.' not in x.text]\n",
    "    \n",
    "    return recent_annc_list_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재밌는 사실. 이 소스코드엔 애초에 tbody가 없었다. 그래서 한참 헤맸다. \n",
    "\n",
    "Chrome selector에선 #listContents > div.table_list > table > tbody > tr:nth-child(1) 라고 나왔지만 이는 브라우저가 insert시킨 것이다. 이런 점을 고려하여 selector를 써야한다. 무조건 Chrome에서 copy selector 한다고 되지 않는다. \n",
    "\n",
    "관련: https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annc_bs2data(annc_bs):\n",
    "    annc_time_regex = re.compile(r'\\d\\d:\\d\\d')\n",
    "    annc_time = annc_bs.find('td', attrs={'class':'cen_txt'}).text\n",
    "    annc_time = annc_time_regex.search(annc_time).group()\n",
    "    \n",
    "    corp_code_regex = re.compile(r'\\d{8}')\n",
    "    corp_code = annc_bs.find('span', {'class':'nobr1'}).a.attrs['onclick']\n",
    "    corp_code = corp_code_regex.search(corp_code).group()\n",
    "    \n",
    "    annc_content_regex = re.compile(r'openReportViewer')\n",
    "    annc_content = annc_bs.find('a', attrs={'onclick':annc_content_regex})  \n",
    "    \n",
    "    annc_title_regex = re.compile('\\\\\\\\.')\n",
    "    annc_content_text = annc_content.text \n",
    "    str_text = \"%r\"%annc_content_text # raw string으로 변환시켜줘야 \\t가 tab으로 인식되지 않는다. \n",
    "    raw_text = str_text[1:-1]\n",
    "    \n",
    "    annc_title = re.sub(annc_title_regex, '', raw_text).strip() \n",
    "    \n",
    "    annc_id_regex = re.compile(r'\\d+')\n",
    "    annc_id = annc_id_regex.search(annc_content.attrs['id']).group()\n",
    "    \n",
    "    data = {}\n",
    "    data['annc_time'] = annc_time\n",
    "    data['corp_code'] = corp_code\n",
    "    data['annc_title'] = annc_title\n",
    "    data['annc_id'] = annc_id\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='color:red'>TODO: raw string으로 바꾸는 부분, 전혀 원리를 모르겠다. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_anncs2df(start_date, end_date, save=False, logging=False, delay=(50, 300)):\n",
    "    start_date = dateutil.parser.parse(str(start_date))\n",
    "    end_date = dateutil.parser.parse(str(end_date))\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date).tolist()\n",
    "    \n",
    "    all_anncs_df = pd.DataFrame(columns=['date', 'annc_time', 'corp_code', 'annc_title', 'annc_id'])\n",
    "    \n",
    "    for i, date in enumerate(date_range):\n",
    "        \n",
    "        if i % delay[0] == 0:\n",
    "            print(f'sleeping for {delay[1]} seconds...')\n",
    "            time.sleep(delay[1])\n",
    "        \n",
    "        anncs_df = pd.DataFrame(columns=['date', 'annc_time', 'corp_code', 'annc_title', 'annc_id'])\n",
    "        anncs_of_the_day = get_recent_annc_list_bs(date.strftime('%Y.%m.%d'))\n",
    "        anncs_of_the_day = [annc_bs2data(annc) for annc in anncs_of_the_day]\n",
    "        anncs_df = anncs_df.append(pd.DataFrame(anncs_of_the_day)) \n",
    "        anncs_df.date = date\n",
    "        \n",
    "        all_anncs_df = all_anncs_df.append(anncs_df)\n",
    "        \n",
    "        if logging:\n",
    "            print(f'Added data on {date}')\n",
    "    \n",
    "    all_anncs_df.loc[:, 'datetime'] = pd.to_datetime(all_anncs_df.date.astype(str) + ' ' + all_anncs_df.annc_time)\n",
    "    all_anncs_df.drop(['date', 'annc_time'], axis=1, inplace=True)\n",
    "    \n",
    "    if save:\n",
    "        all_anncs_df.to_pickle(f\"./all_anncs_df_{start_date.strftime('%Y.%m.%d')}-{end_date.strftime('%Y.%m.%d')}.pkl\")\n",
    "        \n",
    "    return all_anncs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data on 2016-01-01 00:00:00\n",
      "Added data on 2016-01-02 00:00:00\n",
      "Added data on 2016-01-03 00:00:00\n",
      "Added data on 2016-01-04 00:00:00\n",
      "Added data on 2016-01-05 00:00:00\n",
      "Added data on 2016-01-06 00:00:00\n",
      "Added data on 2016-01-07 00:00:00\n",
      "Added data on 2016-01-08 00:00:00\n",
      "Added data on 2016-01-09 00:00:00\n",
      "Added data on 2016-01-10 00:00:00\n",
      "Added data on 2016-01-11 00:00:00\n",
      "Added data on 2016-01-12 00:00:00\n",
      "Added data on 2016-01-13 00:00:00\n",
      "Added data on 2016-01-14 00:00:00\n",
      "Added data on 2016-01-15 00:00:00\n",
      "Added data on 2016-01-16 00:00:00\n",
      "Added data on 2016-01-17 00:00:00\n",
      "Added data on 2016-01-18 00:00:00\n",
      "Added data on 2016-01-19 00:00:00\n",
      "Added data on 2016-01-20 00:00:00\n",
      "Added data on 2016-01-21 00:00:00\n",
      "Added data on 2016-01-22 00:00:00\n",
      "Added data on 2016-01-23 00:00:00\n",
      "Added data on 2016-01-24 00:00:00\n",
      "Added data on 2016-01-25 00:00:00\n",
      "Added data on 2016-01-26 00:00:00\n",
      "Added data on 2016-01-27 00:00:00\n",
      "Added data on 2016-01-28 00:00:00\n",
      "Added data on 2016-01-29 00:00:00\n",
      "Added data on 2016-01-30 00:00:00\n",
      "Added data on 2016-01-31 00:00:00\n",
      "Added data on 2016-02-01 00:00:00\n",
      "Added data on 2016-02-02 00:00:00\n",
      "Added data on 2016-02-03 00:00:00\n",
      "Added data on 2016-02-04 00:00:00\n",
      "Added data on 2016-02-05 00:00:00\n",
      "Added data on 2016-02-06 00:00:00\n",
      "Added data on 2016-02-07 00:00:00\n",
      "Added data on 2016-02-08 00:00:00\n",
      "Added data on 2016-02-09 00:00:00\n",
      "Added data on 2016-02-10 00:00:00\n",
      "Added data on 2016-02-11 00:00:00\n",
      "Added data on 2016-02-12 00:00:00\n",
      "Added data on 2016-02-13 00:00:00\n",
      "Added data on 2016-02-14 00:00:00\n",
      "Added data on 2016-02-15 00:00:00\n",
      "Added data on 2016-02-16 00:00:00\n",
      "Added data on 2016-02-17 00:00:00\n",
      "Added data on 2016-02-18 00:00:00\n",
      "Added data on 2016-02-19 00:00:00\n",
      "Added data on 2016-02-20 00:00:00\n",
      "Added data on 2016-02-21 00:00:00\n",
      "Added data on 2016-02-22 00:00:00\n",
      "Added data on 2016-02-23 00:00:00\n",
      "Added data on 2016-02-24 00:00:00\n",
      "Added data on 2016-02-25 00:00:00\n",
      "Added data on 2016-02-26 00:00:00\n",
      "Added data on 2016-02-27 00:00:00\n",
      "Added data on 2016-02-28 00:00:00\n",
      "Added data on 2016-02-29 00:00:00\n",
      "Added data on 2016-03-01 00:00:00\n",
      "Added data on 2016-03-02 00:00:00\n",
      "Added data on 2016-03-03 00:00:00\n",
      "Added data on 2016-03-04 00:00:00\n",
      "Added data on 2016-03-05 00:00:00\n",
      "Added data on 2016-03-06 00:00:00\n",
      "Added data on 2016-03-07 00:00:00\n",
      "Added data on 2016-03-08 00:00:00\n",
      "Added data on 2016-03-09 00:00:00\n",
      "Added data on 2016-03-10 00:00:00\n",
      "Added data on 2016-03-11 00:00:00\n",
      "Added data on 2016-03-12 00:00:00\n",
      "Added data on 2016-03-13 00:00:00\n",
      "Added data on 2016-03-14 00:00:00\n",
      "Added data on 2016-03-15 00:00:00\n",
      "Added data on 2016-03-16 00:00:00\n",
      "Added data on 2016-03-17 00:00:00\n",
      "Added data on 2016-03-18 00:00:00\n",
      "Added data on 2016-03-19 00:00:00\n",
      "Added data on 2016-03-20 00:00:00\n",
      "Added data on 2016-03-21 00:00:00\n",
      "Added data on 2016-03-22 00:00:00\n",
      "Added data on 2016-03-23 00:00:00\n",
      "Added data on 2016-03-24 00:00:00\n",
      "Added data on 2016-03-25 00:00:00\n",
      "Added data on 2016-03-26 00:00:00\n",
      "Added data on 2016-03-27 00:00:00\n",
      "Added data on 2016-03-28 00:00:00\n",
      "Added data on 2016-03-29 00:00:00\n",
      "Added data on 2016-03-30 00:00:00\n",
      "Added data on 2016-03-31 00:00:00\n",
      "Added data on 2016-04-01 00:00:00\n",
      "Added data on 2016-04-02 00:00:00\n",
      "Added data on 2016-04-03 00:00:00\n",
      "Added data on 2016-04-04 00:00:00\n",
      "Added data on 2016-04-05 00:00:00\n",
      "Added data on 2016-04-06 00:00:00\n",
      "Added data on 2016-04-07 00:00:00\n",
      "Added data on 2016-04-08 00:00:00\n",
      "Added data on 2016-04-09 00:00:00\n",
      "Added data on 2016-04-10 00:00:00\n",
      "Added data on 2016-04-11 00:00:00\n",
      "Added data on 2016-04-12 00:00:00\n",
      "Added data on 2016-04-13 00:00:00\n",
      "Added data on 2016-04-14 00:00:00\n",
      "Added data on 2016-04-15 00:00:00\n",
      "Added data on 2016-04-16 00:00:00\n",
      "Added data on 2016-04-17 00:00:00\n",
      "Added data on 2016-04-18 00:00:00\n",
      "Added data on 2016-04-19 00:00:00\n",
      "Added data on 2016-04-20 00:00:00\n",
      "Added data on 2016-04-21 00:00:00\n",
      "Added data on 2016-04-22 00:00:00\n",
      "Added data on 2016-04-23 00:00:00\n",
      "Added data on 2016-04-24 00:00:00\n",
      "Added data on 2016-04-25 00:00:00\n",
      "Added data on 2016-04-26 00:00:00\n",
      "Added data on 2016-04-27 00:00:00\n",
      "Added data on 2016-04-28 00:00:00\n",
      "Added data on 2016-04-29 00:00:00\n",
      "Added data on 2016-04-30 00:00:00\n",
      "Added data on 2016-05-01 00:00:00\n",
      "Added data on 2016-05-02 00:00:00\n",
      "Added data on 2016-05-03 00:00:00\n",
      "Added data on 2016-05-04 00:00:00\n",
      "Added data on 2016-05-05 00:00:00\n",
      "Added data on 2016-05-06 00:00:00\n",
      "Added data on 2016-05-07 00:00:00\n",
      "Added data on 2016-05-08 00:00:00\n",
      "Added data on 2016-05-09 00:00:00\n",
      "Added data on 2016-05-10 00:00:00\n",
      "Added data on 2016-05-11 00:00:00\n",
      "Added data on 2016-05-12 00:00:00\n",
      "Added data on 2016-05-13 00:00:00\n",
      "Added data on 2016-05-14 00:00:00\n",
      "Added data on 2016-05-15 00:00:00\n",
      "Added data on 2016-05-16 00:00:00\n",
      "Added data on 2016-05-17 00:00:00\n",
      "Added data on 2016-05-18 00:00:00\n",
      "Added data on 2016-05-19 00:00:00\n",
      "Added data on 2016-05-20 00:00:00\n",
      "Added data on 2016-05-21 00:00:00\n",
      "Added data on 2016-05-22 00:00:00\n",
      "Added data on 2016-05-23 00:00:00\n",
      "Added data on 2016-05-24 00:00:00\n",
      "Added data on 2016-05-25 00:00:00\n",
      "Added data on 2016-05-26 00:00:00\n",
      "Added data on 2016-05-27 00:00:00\n",
      "Added data on 2016-05-28 00:00:00\n",
      "Added data on 2016-05-29 00:00:00\n",
      "Added data on 2016-05-30 00:00:00\n",
      "Added data on 2016-05-31 00:00:00\n",
      "Added data on 2016-06-01 00:00:00\n",
      "Added data on 2016-06-02 00:00:00\n",
      "Added data on 2016-06-03 00:00:00\n",
      "Added data on 2016-06-04 00:00:00\n",
      "Added data on 2016-06-05 00:00:00\n",
      "Added data on 2016-06-06 00:00:00\n",
      "Added data on 2016-06-07 00:00:00\n",
      "Added data on 2016-06-08 00:00:00\n",
      "Added data on 2016-06-09 00:00:00\n",
      "Added data on 2016-06-10 00:00:00\n",
      "Added data on 2016-06-11 00:00:00\n",
      "Added data on 2016-06-12 00:00:00\n",
      "Added data on 2016-06-13 00:00:00\n",
      "Added data on 2016-06-14 00:00:00\n",
      "Added data on 2016-06-15 00:00:00\n",
      "Added data on 2016-06-16 00:00:00\n",
      "Added data on 2016-06-17 00:00:00\n",
      "Added data on 2016-06-18 00:00:00\n",
      "Added data on 2016-06-19 00:00:00\n",
      "Added data on 2016-06-20 00:00:00\n",
      "Added data on 2016-06-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recent_anncs2df(20160101, 20200404, save=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
